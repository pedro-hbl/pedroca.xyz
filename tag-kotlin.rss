<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Pedro Lopes</title><link></link><description>Comput. Sci.</description><pubDate>Tue, 29 Apr 2025 00:00:00 GMT</pubDate><lastBuildDate>Wed, 30 Apr 2025 04:12:00 GMT</lastBuildDate><generator>marmite</generator><item><title>Reactive Programming(Paradigm) and how to work with it in Spring</title><link>/reactive-programming-spring.html</link><author>pedrohbl_</author><category>java</category><category>kotlin</category><category>spring</category><category>reactive</category><category>webflux</category><category>project-reactor</category><category>back-pressure</category><category>concurrency</category><category>messaging</category><category>kafka</category><guid>/reactive-programming-spring.html</guid><pubDate>Tue, 29 Apr 2025 00:00:00 GMT</pubDate><source url="">tag-kotlin</source><content:encoded><![CDATA[<!-- Content Injected to every content markdown header -->
<h2><a href="#introduction" aria-hidden="true" class="anchor" id="introduction"></a>Introduction</h2>
<p>It is evident that modern applications are facing increasingly demanding requirements. The systems we built just a few years ago, monolithic applications or even some simple CRUD microservices serving modest user bases are now becoming to struggle when needed to handle thousands of concurrent users, each expecting near-instantaneous responses. This shift has pushed some developers to rethink fundamental architectural patterns.</p>
<p>So, there's this book called &quot;Designing Data-Intensive Applications&quot; where Martin Kleppmann describes this evolution perfectly. Today's users expect millisecond responses whether they're the only person on your site or sharing it with thousands of others. It's a reality that forces us to build applications that are more scalable, elastic, robust, and resilient than ever before.</p>
<p>In this environment of high performance APIs, there's a paradigm called &quot;Reactive Programming&quot;, which has emerged as a compelling solution to these challenges. What started as a niche paradigm has moved toward the mainstream, particularly for applications dealing with high concurrency or integration with asynchronous systems. If you've attended a Java/Kotlin technical interview recently, you've likely encountered questions about reactive programming‚Äîperhaps wondering if it's just another industry buzzword or genuinely the answer to modern performance requirements.</p>
<p>In this post I'll be focusing on reactive programming in Spring. Basically covering some topics below:</p>
<ol>
<li><strong>What is reactive programming</strong></li>
<li><strong>How Spring implements the reactive paradigm</strong></li>
<li><strong>Benefits you can expect</strong></li>
<li><strong>Limitations</strong></li>
<li><strong>Common anti-patterns</strong></li>
<li><strong>Inter-service communication in reactive systems</strong></li>
<li><strong>Best practices</strong></li>
</ol>
<h2><a href="#what-is-reactive-programming" aria-hidden="true" class="anchor" id="what-is-reactive-programming"></a>What Is Reactive Programming?</h2>
<p>Reactive programming is a declarative programming paradigm concerned with data streams and the propagation of change. Instead of pulling data (as in imperative programming), reactive programming lets you set up data streams where changes propagate automatically. An example could be the difference between checking your email every 5 minutes (imperative) versus getting push notifications when new emails arrive (reactive).</p>
<p>There is a source of truth about the paradigm which is <a href="https://www.reactivemanifesto.org/">Reactive Manifesto</a>(you should probably check it out as well), which emerged from the need to build systems that are:</p>
<ul>
<li><strong>Responsive</strong>: They respond in a timely manner</li>
<li><strong>Resilient</strong>: They stay responsive in the face of failure</li>
<li><strong>Elastic</strong>: They stay responsive under varying workload</li>
<li><strong>Message-driven</strong>: They rely on asynchronous message-passing</li>
</ul>
<p>This isn't just theoretical as these principles directly address real-world challenges in modern distributed systems, as our applications scaled up to serve thousands of concurrent users, the limitations of thread-per-request models became really painful.</p>
<h3><a href="#the-shift-is-basically-threads---events" aria-hidden="true" class="anchor" id="the-shift-is-basically-threads---events"></a>The shift is basically: Threads -&gt; Events</h3>
<p>Traditional Spring MVC applications typically use a thread-per-request model. If your application receives 200 concurrent requests, it needs approximately 200 threads to handle them. This is actually fine for modest concurrency and standard applications, but there are some points to take care when it comes to high concurrency levels and higher tps(lets say above 1000tps):</p>
<ol>
<li><strong>Threads are expensive</strong>: Each thread consumes memory (often ~1MB of stack space)</li>
<li><strong>Context switching is costly</strong>: The CPU spends time switching between threads</li>
<li><strong>Most threads spend their time waiting</strong>: Threads sit idle during I/O operations</li>
</ol>
<p>Consider this example of a traditional Spring MVC endpoint that calls an external service(this is probably how your API works):</p>
<pre><code class="language-java">@GetMapping(&quot;/customers/{id}&quot;)
public Customer getCustomer(@PathVariable Long id) {
    // this thread blocks while waiting for the database
    return customerRepository.findById(id)
           .orElseThrow(() -&gt; new CustomerNotFoundException(id));
}
</code></pre>
<p>During the database call, this thread is blocked‚Äîconsuming resources but doing no useful work. Now multiply this by thousands of concurrent requests, and you can see why this model struggles at scale =D.</p>
<p>Reactive programming takes a different approach, using a small number of threads and an event loop model similar to Node.js:</p>
<pre><code class="language-java">@GetMapping(&quot;/customers/{id}&quot;)
public Mono&lt;Customer&gt; getCustomer(@PathVariable Long id) {
    // this doesn't block - it returns immediately with a &quot;promise&quot; of a customer
    return customerRepository.findById(id)
           .switchIfEmpty(Mono.error(new CustomerNotFoundException(id)));
}
</code></pre>
<p>In this reactive version, the thread handling the request isn't blocked during the database call. Instead, it processes other requests and is notified when the data is ready. This allows each thread to handle many more requests, significantly improving resource utilization.</p>
<h3><a href="#key-concepts-in-reactive-programming" aria-hidden="true" class="anchor" id="key-concepts-in-reactive-programming"></a>Key Concepts in Reactive Programming</h3>
<p>To understand reactive programming, you'll need a few fundamental concepts:</p>
<ol>
<li><strong>Publisher/Subscriber Model</strong>: Data sources emit values, and subscribers process them</li>
<li><strong>Backpressure</strong>: Subscribers can tell publishers to slow down if they can't keep up (You can find a fancier description on the manifesto if you want)</li>
<li><strong>Composition</strong>: Operations can be chained together to create complex data flows</li>
<li><strong>Error Handling</strong>: Errors propagate through the stream and can be handled at any point</li>
</ol>
<blockquote>
<p><strong><em>NOTE:</em></strong> <em>(Easter Egg)</em> If you look closely at reactive programming composition model, you might notice there's a reference to functional programming concepts like monads, functors, and applicatives. This is not a coincidence :) ... In fact, <code>Mono&lt;T&gt;</code> and <code>Flux&lt;T&gt;</code> are essentially monadic containers that let you compose operations while maintaining context around success, failure, and completion. If you're interested in some of this topics, check out my previous post on <a href="kotlin-result-functional.html">how monads can improve error handling in Kotlin</a> - many of the same principles apply to reactive streams</p>
</blockquote>
<h2><a href="#reactive-programming-in-spring" aria-hidden="true" class="anchor" id="reactive-programming-in-spring"></a>Reactive Programming in Spring</h2>
<p>Spring's reactive support is primarily built on <a href="https://projectreactor.io/">Project Reactor</a>, which implements the Reactive Streams specification and provides two main types:</p>
<ol>
<li><strong>Mono<T></strong>: Represents a stream of 0 or 1 item (Like an <code>Optional&lt;T&gt;</code>)</li>
<li><strong>Flux<T></strong>: Represents a stream of 0 to N items (Like a <code>List&lt;T&gt;</code>)</li>
</ol>
<p>These building blocks are then integrated throughout the Spring ecosystem:</p>
<ul>
<li><strong>Spring WebFlux</strong>: A reactive alternative to Spring MVC</li>
<li><strong>Spring Data Reactive</strong>: Reactive repositories for various databases</li>
<li><strong>Spring Cloud Gateway</strong>: A reactive API gateway</li>
<li><strong>Spring Security Reactive</strong>: Security for reactive applications</li>
</ul>
<p>This is how a reactive Spring application looks like:</p>
<pre><code class="language-kotlin">@RestController
class CustomerController(private val customerRepository: ReactiveCustomerRepository) {
    
    @GetMapping(&quot;/customers&quot;)
    fun getAllCustomers(): Flux&lt;Customer&gt; {
        return customerRepository.findAll()
    }
    
    @GetMapping(&quot;/customers/{id}&quot;)
    fun getCustomer(@PathVariable id: Long): Mono&lt;Customer&gt; {
        return customerRepository.findById(id)
            .switchIfEmpty(Mono.error(CustomerNotFoundException(id)))
    }
    
    @PostMapping(&quot;/customers&quot;)
    fun createCustomer(@RequestBody customer: Mono&lt;Customer&gt;): Mono&lt;Customer&gt; {
        return customer.flatMap { customerRepository.save(it) }
    }
}
</code></pre>
<p>Notice how everything returns either a <code>Mono</code> or a <code>Flux</code>, maintaining the reactive nature throughout. This is crucial in reactive programming, if even one operation blocks a thread, that thread is stuck waiting and can't process other requests. A single blocking call destroys the advantage of reactive programming: the ability to handle many requests with few threads. It doesn't matter if 99% of your code is reactive‚Äîthat one blocking call will limit your entire application's throughput to what that blocked thread can handle.</p>
<h3><a href="#understanding-the-reactive-flow" aria-hidden="true" class="anchor" id="understanding-the-reactive-flow"></a>Understanding the Reactive Flow</h3>
<p>To understand how data flows through a reactive system, let's trace a request through a typical Spring WebFlux(reactive) application:</p>
<ol>
<li><strong>Request arrives</strong>: The server accepts the HTTP request on one of its event loop threads</li>
<li><strong>Handler mapping</strong>: The request is routed to the appropriate controller method</li>
<li><strong>Controller processing</strong>: The controller returns a <code>Mono</code> or <code>Flux</code> representing the future response</li>
<li><strong>Repository access</strong>: The repository asynchronously fetches data without blocking</li>
<li><strong>Response assembly</strong>: Once data is available, it's assembled into a response</li>
<li><strong>Response sent</strong>: The response is written back to the client</li>
</ol>
<p>At each step, the thread isn't waiting so it can process other requests while asynchronous operations complete. This is where the efficiency gains come from.</p>
<h2><a href="#benefits-of-reactive-programming-in-spring" aria-hidden="true" class="anchor" id="benefits-of-reactive-programming-in-spring"></a>Benefits of Reactive Programming in Spring</h2>
<h3><a href="#1-improved-resource-utilization" aria-hidden="true" class="anchor" id="1-improved-resource-utilization"></a>1. Improved Resource Utilization</h3>
<p>Reactive applications can handle more concurrent requests with fewer threads, leading to better CPU and memory utilization. According to research published by the Spring team [9], reactive applications generally require fewer resources to achieve the same throughput levels as their servlet-based counterparts. The efficiency gains become more pronounced as concurrency increases, particularly for I/O-bound applications.</p>
<p>The key factors behind this improvement are:</p>
<ul>
<li>Thread efficiency: Fewer threads handle more requests</li>
<li>Reduced context switching: Lower CPU overhead from thread management</li>
<li>Better I/O utilization: Non-blocking I/O operations maximize resource usage</li>
</ul>
<p>When your application needs to scale to handle thousands of concurrent connections, these advantages can bring hardware savings or throughput improvements.</p>
<h3><a href="#2-more-responsive-under-load" aria-hidden="true" class="anchor" id="2-more-responsive-under-load"></a>2. More Responsive Under Load</h3>
<p>One of the most compelling benefits of reactive systems is how they degrade under load. Traditional systems might become completely unresponsive when overloaded, while reactive systems typically experience graceful degradation.</p>
<p>Consider a scenario where your system suddenly receives a spike in traffic:</p>
<ul>
<li><strong>Traditional approach</strong>: Thread pool gets exhausted, requests queue up, and everything slows down</li>
<li><strong>Reactive approach</strong>: System processes what it can based on available resources and applies backpressure</li>
</ul>
<p>Look at this example</p>
<pre><code class="language-kotlin">// traditional approach - webmvc: might crash under heavy load
@PostMapping(&quot;/send-batch&quot;)
fun sendNotifications(@RequestBody notifications: List&lt;Notification&gt;): ResponseEntity&lt;String&gt; {
    notifications.forEach { notificationService.send(it) }
    return ResponseEntity.ok(&quot;Notifications queued&quot;)
}

// reactive approach - handles load gracefully with backpressure :_)
@PostMapping(&quot;/send-batch&quot;)
fun sendNotifications(@RequestBody notifications: Flux&lt;Notification&gt;): Mono&lt;ResponseEntity&lt;String&gt;&gt; {
    return notifications
        .flatMap({ notification -&gt; notificationService.send(notification) }, 
                 concurrency = 10) // control concurrency
        .then(Mono.just(ResponseEntity.ok(&quot;Notifications processed&quot;)))
}
</code></pre>
<p>The reactive version controls how many notifications are processed concurrently, preventing system overload.</p>
<h3><a href="#3-better-integration-with-async-systems" aria-hidden="true" class="anchor" id="3-better-integration-with-async-systems"></a>3. Better Integration with Async Systems</h3>
<p>Modern applications often integrate with asynchronous systems like message queues, event streams, and webhooks. Reactive programming provides a natural fit for these inherently asynchronous interactions.</p>
<p>Compare these approaches for consuming Kafka messages:</p>
<p><strong>Traditional (@KafkaListener):</strong></p>
<pre><code class="language-kotlin">@Service
class TraditionalKafkaListener {
    @KafkaListener(topics = [&quot;transactions&quot;])
    fun processTransaction(transaction: Transaction) {
        if (transaction.amount &gt; 0) {
            try {
                val result = transactionProcessor.process(transaction)
            } catch (e: Exception) {
                logger.error(&quot;Failed to process transaction&quot;, e)
            }
        }
    }
}
</code></pre>
<p><strong>Reactive:</strong></p>
<pre><code class="language-kotlin">@Service
class ReactiveProcessor(private val kafkaReceiver: KafkaReceiver&lt;String, Transaction&gt;) {
    fun processTransactions() {
        kafkaReceiver.receive()
            .filter { it.value().amount &gt; 0 }
            .flatMap { transactionProcessor.process(it.value()) }
            .doOnError { e -&gt; logger.error(&quot;Error in processing&quot;, e) }
            .retry(3)
            .subscribe()
    }
}
</code></pre>
<p><strong>What is the KafkaReceiver?</strong><br />
<code>KafkaReceiver</code> comes from the <code>reactor-kafka</code> library, a reactive Kafka client built on Project Reactor. Unlike the traditional <code>@KafkaListener</code> which processes messages one by one with blocking threads, <code>KafkaReceiver</code> connects to Kafka topics and transforms the incoming messages into a <code>Flux</code> stream. This allows you to process Kafka messages using the full reactive streams toolkit - applying transformations, filtering, error handling, and backpressure - all non-blocking.</p>
<h3><a href="#4-enhanced-resilience-patterns" aria-hidden="true" class="anchor" id="4-enhanced-resilience-patterns"></a>4. Enhanced Resilience Patterns</h3>
<p>The reactive programming model makes it easier to implement resilience patterns like circuit breakers, bulkheads, and timeouts. For example, implementing a timeout pattern is really simples, look:</p>
<pre><code class="language-kotlin">fun getProductDetails(id: String): Mono&lt;ProductDetails&gt; {
    return webClient.get()
        .uri(&quot;/products/{id}&quot;, id)
        .retrieve()
        .bodyToMono(ProductDetails::class.java)
        .timeout(Duration.ofSeconds(1))
        .onErrorResume { e -&gt; 
            when (e) {
                // this code automatically falls back to a default response if the product service doesn't respond within 1s
                is TimeoutException -&gt; Mono.just(ProductDetails.fallback(id)) 
                else -&gt; Mono.error(e)
            }
        }
}
</code></pre>
<h2><a href="#limitations" aria-hidden="true" class="anchor" id="limitations"></a>Limitations</h2>
<p>Despite its benefits, reactive programming isn't without challenges. Here are some of the issues you'll likely encounter:</p>
<h3><a href="#1-learning-curve" aria-hidden="true" class="anchor" id="1-learning-curve"></a>1. Learning Curve</h3>
<p>Reactive programming requires a significant mental shift from imperative programming. Concepts like backpressure, cold vs. hot streams, and functional composition are really hard when you step in.</p>
<p>In my experience, it takes developers around 3-6 months to become truly comfortable with reactive programming, and even longer to master advanced concepts like debugging complex reactive pipelines(I can't do this either lol).</p>
<h3><a href="#2-debug-complexity" aria-hidden="true" class="anchor" id="2-debug-complexity"></a>2. Debug Complexity</h3>
<p>One of the most frustrating aspects of reactive programming is debugging. Stack traces often don't tell you where the actual problem occurred, as operations are composed and executed asynchronously.</p>
<p>Consider this stack trace from a reactive application:</p>
<pre><code>java.lang.NullPointerException: Cannot invoke &quot;Customer.getName()&quot; because &quot;customer&quot; is null
    at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
    at reactor.core.publisher.FluxPeekFuseable$PeekFuseableSubscriber.onNext(FluxPeekFuseable.java:210)
    at reactor.core.publisher.FluxFilter$FilterSubscriber.onNext(FluxFilter.java:113)
    at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:426)
    ...more reactor internals...
</code></pre>
<p>Good luck finding where in your code the <code>null</code> customer originated...</p>
<p>Sometimes to address this, you can use:</p>
<ul>
<li><code>checkpoint()</code> operators to add context to stack traces</li>
<li><code>log()</code> to see the data flow at specific points (no miracle here :c)</li>
</ul>
<h3><a href="#3-ecosystem-maturity" aria-hidden="true" class="anchor" id="3-ecosystem-maturity"></a>3. Ecosystem Maturity</h3>
<p>While the core reactive libraries in Spring are mature, some parts of the ecosystem are still beign built. Many third-party libraries and legacy systems don't provide reactive APIs, requiring you to integrate reactive and non-reactive code carefully.</p>
<ul>
<li><strong>Database Drivers</strong>: While R2DBC provides reactive SQL access, many specialized database drivers still only offer blocking APIs</li>
<li><strong>Third-Party Integrations</strong>: Many payment gateways, external APIs, and legacy systems haven't adopted reactive patterns</li>
<li><strong>File Systems</strong>: Local file operations often still rely on blocking I/O</li>
<li><strong>JPA/Hibernate</strong>: Traditional ORM tools aren't designed for reactive use cases, requiring alternative approaches like R2DBC</li>
</ul>
<p>For example, if you're using a library with only blocking APIs, you'll need to isolate it in a separate thread pool:</p>
<pre><code class="language-kotlin">fun callBlockingLibrary(): Mono&lt;Result&gt; {
    return Mono.fromCallable {
        blockingLibrary.doSomething() // Blocking call
    }.subscribeOn(Schedulers.boundedElastic())
}
</code></pre>
<p>Basically <code>Schedulers.boundedElastic()</code> creates a dedicated pool of threads specifically designed for blocking operations. These threads are separate from your application's main event loop threads, so it should not mess your entire codebase with a single blocking code.</p>
<h3><a href="#4-operational-complexity" aria-hidden="true" class="anchor" id="4-operational-complexity"></a>4. Operational Complexity</h3>
<p>Reactive systems introduce some operational challenges that differ from traditional applications. Here you can find some:</p>
<h4><a href="#metrics-collection" aria-hidden="true" class="anchor" id="metrics-collection"></a>Metrics Collection</h4>
<p>In traditional applications, metrics are straightforward: one thread, one request, one timer. In reactive applications, operations flow through multiple asynchronous stages, making measurement more complex.</p>
<p><strong>Solution:</strong> Using reactive metrics tools:</p>
<pre><code class="language-kotlin">fun processOrder(orderId: String): Mono&lt;OrderResult&gt; {
    // create a timer sample at the start
    val sample = Timer.start(meterRegistry)
    
    return orderRepository.findById(orderId)
        .flatMap { order -&gt; 
            paymentService.process(order)
        }
        .flatMap { payment -&gt;
            notificationService.notify(payment)
        }
        .doFinally { signalType -&gt;
            // record the duration when the flow completes (success or error)
            sample.stop(meterRegistry.timer(&quot;order.processing&quot;, 
                &quot;outcome&quot;, signalType.name.toLowerCase()))
        }
}
</code></pre>
<p>Micrometer's <code>Timer.Sample</code> allows you to track the entire reactive flow, including error states.</p>
<h4><a href="#distributed-tracing" aria-hidden="true" class="anchor" id="distributed-tracing"></a>Distributed Tracing</h4>
<p>When requests span multiple services, tracing becomes essential. But reactive flows complicate this by breaking the thread-per-request model.</p>
<p><strong>Solution:</strong> Spring Boot 3.x integrates Micrometer Tracing (which replaces Spring Cloud Sleuth):</p>
<pre><code class="language-kotlin">// application.yml configs
spring:
  application:
    name: order-service
  tracing:
    sampling:
      probability: 1.0  # all requests
    propagation:
      type: w3c        
</code></pre>
<p>With proper configuration, trace context automatically propagates through reactive chains, even across service boundaries via HTTP or messaging:</p>
<pre><code class="language-kotlin">@RestController
class OrderController(private val orderService: OrderService) {
    
    @GetMapping(&quot;/orders/{id}&quot;)
    fun getOrder(@PathVariable id: String): Mono&lt;OrderDetails&gt; {
        // traceId and spanId automatically propagate through the reactive chain
        return orderService.findOrder(id)
            .flatMap { order -&gt; 
                // creates a new span for this operation
                Mono.deferContextual { ctx -&gt; //get the current tracking information
                    val tracer = ctx.get(Tracer::class.java)
                    //here we create and start a new span
                    tracer.nextSpan()
                    .name(&quot;enrich-order-details&quot;)
                    .withTag(&quot;orderId&quot;, id)
                    .start()
                    .use { _ -&gt;
                        enrichmentService.addDetails(order) 
                    }
                }
            }
    }
}
</code></pre>
<p>The <code>.use { }</code> syntax from Kotlin ensures the span is closed even if an exception occurs, similar to a try-with-resources in Java.</p>
<h2><a href="#common-anti-patterns-in-reactive-spring" aria-hidden="true" class="anchor" id="common-anti-patterns-in-reactive-spring"></a>Common Anti-Patterns in Reactive Spring</h2>
<p>I've done some research over anti patterns around the use of reactive programming in Spring, but being really honest I did not found a lot of useful stuff, so I'll put some points that I've faced in production environments I've worked on, so you should probably avoid them.</p>
<h3><a href="#1-blocking-inside-reactive-code" aria-hidden="true" class="anchor" id="1-blocking-inside-reactive-code"></a>1. Blocking Inside Reactive Code</h3>
<p>The cardinal sin of reactive programming is introducing blocking calls in your reactive pipeline:</p>
<pre><code class="language-kotlin">// DON'T DO THIS
fun getCustomerDetails(id: Long): Mono&lt;CustomerDetails&gt; {
    return customerRepository.findById(id)
        .map { customer -&gt;
            // blocking call inside reactive pipeline
            val creditScore = blockingCreditScoreService.getScore(customer.id)
            CustomerDetails(customer, creditScore)
        }
}
</code></pre>
<p>This code defeats the purpose of reactive programming by blocking threads within the reactive flow. Instead:</p>
<pre><code class="language-kotlin">fun getCustomerDetails(id: Long): Mono&lt;CustomerDetails&gt; {
    return customerRepository.findById(id)
        .flatMap { customer -&gt;
            // wrap the blocking call with Mono.fromCallable and move to dedicated scheduler
            Mono.fromCallable { blockingCreditScoreService.getScore(customer.id) }
                .subscribeOn(Schedulers.boundedElastic())
                .map { creditScore -&gt; CustomerDetails(customer, creditScore) }
        }
}
</code></pre>
<h3><a href="#2-reactive-overkill" aria-hidden="true" class="anchor" id="2-reactive-overkill"></a>2. Reactive Overkill</h3>
<p>Not every application needs to be reactive. If your application doesn't have high concurrency requirements or doesn't interact with asynchronous systems, reactive programming might introduce unnecessary complexity.</p>
<p>For a simple CRUD application with modest traffic, traditional Spring MVC is often simpler and more than adequate.</p>
<h4><a href="#when-to-consider-reactive-Ô∏è-akcthually" aria-hidden="true" class="anchor" id="when-to-consider-reactive-Ô∏è-akcthually"></a>When to Consider Reactive ‚òùÔ∏èü§ì akcthually</h4>
<p>While there's no universal threshold, research and real-world experience suggest these approximate guidelines:</p>
<ul>
<li>
<p><strong>Concurrent Users</strong>: Consider reactive when expecting &gt;500 concurrent users on modest hardware. A 2022 study by Krefter et al. [11] found that Spring MVC applications started showing thread pool saturation around 800-1000 concurrent users on 4-core machines, while reactive applications maintained consistent response times.</p>
</li>
<li>
<p><strong>Transactions Per Second</strong>: Traditional MVC typically handles up to ~1000 TPS efficiently on standard hardware before thread pool tuning becomes critical. Reactive shows clearer benefits beyond this point.</p>
</li>
<li>
<p><strong>Response Time Under Load</strong>: If your 99th percentile response time must stay under 200-300ms during traffic spikes, reactive offers more consistent latency distributions when properly implemented.</p>
</li>
<li>
<p><strong>I/O Wait Ratios</strong>: If profiling shows your application spends &gt;30% of time in I/O wait states, reactive programming's efficiency gains become more pronounced.</p>
</li>
<li>
<p><strong>Connection Lifespan</strong>: For applications with long-lived connections (WebSockets, SSE) or streaming responses, consider reactive once you expect &gt;1000 simultaneous connections.</p>
</li>
</ul>
<h3><a href="#3-ignoring-backpressure" aria-hidden="true" class="anchor" id="3-ignoring-backpressure"></a>3. Ignoring Backpressure</h3>
<p>Backpressure is one of the key features of reactive streams, allowing consumers to signal producers to slow down. Ignoring backpressure can lead to <code>OutOfMemoryError</code> when producers emit faster than consumers can handle.</p>
<p>Picture this example:</p>
<pre><code class="language-kotlin">// no backpressure handling
fileService.readLargeFile(path) // returns Flux&lt;Chunk&gt;
    .flatMap { chunk -&gt; processChunk(chunk) } // unbounded concurrency
</code></pre>
<p>Instead, specify concurrency limits:</p>
<pre><code class="language-kotlin">// safely controls concurrency
fileService.readLargeFile(path)
    .flatMap({ chunk -&gt; processChunk(chunk) }, concurrency = 10) // limited concurrency
</code></pre>
<h2><a href="#inter-service-communication-in-reactive-systems" aria-hidden="true" class="anchor" id="inter-service-communication-in-reactive-systems"></a>Inter-Service Communication in Reactive Systems</h2>
<p>Modern applications rarely exist in isolation. They communicate with other services, databases, message queues, and external APIs. Here's how to handle these communications reactively:</p>
<h3><a href="#1-http-communication-with-webclient" aria-hidden="true" class="anchor" id="1-http-communication-with-webclient"></a>1. HTTP Communication with WebClient</h3>
<p>Spring WebFlux provides <code>WebClient</code>, a reactive alternative to <code>RestTemplate</code>:</p>
<pre><code class="language-kotlin">@Service
class ProductService(private val webClient: WebClient) {
    
    fun getProductDetails(id: String): Mono&lt;ProductDetails&gt; {
        return webClient.get()
            .uri(&quot;/products/{id}&quot;, id)
            .retrieve()
            .bodyToMono(ProductDetails::class.java)
            .timeout(Duration.ofSeconds(1))
            .onErrorResume(WebClientResponseException::class.java) { e -&gt;
                when (e.statusCode) {
                    HttpStatus.NOT_FOUND -&gt; Mono.empty()
                    else -&gt; Mono.error(e)
                }
            }
    }
}
</code></pre>
<p><code>WebClient</code> supports streaming responses, backpressure, and non-blocking I/O, making it VERY GOOD for reactive applications.</p>
<h3><a href="#2-reactive-database-access" aria-hidden="true" class="anchor" id="2-reactive-database-access"></a>2. Reactive Database Access</h3>
<p>Spring Data Reactive provides reactive repositories for various databases:</p>
<pre><code class="language-kotlin">@Repository
interface CustomerRepository : ReactiveCrudRepository&lt;Customer, Long&gt; {
    
    fun findByLastName(lastName: String): Flux&lt;Customer&gt;
    
    fun countByStatus(status: CustomerStatus): Mono&lt;Long&gt;
}
</code></pre>
<p>Some of the supported databases include:</p>
<ul>
<li>MongoDB (Spring Data MongoDB Reactive)</li>
<li>Cassandra (Spring Data Cassandra Reactive)</li>
<li>Redis (Spring Data Redis Reactive)</li>
<li>R2DBC for relational databases (MySQL, PostgreSQL, MS SQL, H2...)</li>
<li>Using SDK of AWS for services like DynamoDB with async access may also work (if you do some work around the return(completable future) to parse it into a Mono/Flux)</li>
</ul>
<h3><a href="#3-circuit-breaking-and-resilience" aria-hidden="true" class="anchor" id="3-circuit-breaking-and-resilience"></a>3. Circuit Breaking and Resilience</h3>
<p>For resilient inter-service communication, Resilience4j provides reactive circuit breakers:</p>
<pre><code class="language-kotlin">@Service
class ResilientProductService(
    private val webClient: WebClient,
    private val circuitBreakerRegistry: CircuitBreakerRegistry
) {
    
    private val circuitBreaker = circuitBreakerRegistry.circuitBreaker(&quot;productService&quot;)
    
    fun getProductDetails(id: String): Mono&lt;ProductDetails&gt; {
        return ReactiveCircuitBreaker.create(circuitBreaker)
            .run(
                webClient.get()
                    .uri(&quot;/products/{id}&quot;, id)
                    .retrieve()
                    .bodyToMono(ProductDetails::class.java),
                { e -&gt; Mono.just(ProductDetails.fallback(id)) }
            )
    }
}
</code></pre>
<p>This pattern prevents cascading failures when downstream services are unresponsive.</p>
<h2><a href="#best-practices-for-reactive-spring-applications" aria-hidden="true" class="anchor" id="best-practices-for-reactive-spring-applications"></a>Best Practices for Reactive Spring Applications</h2>
<p>Based on my experience, here are some best practices for building reactive Spring applications:</p>
<h3><a href="#1-reactive-all-the-way-through" aria-hidden="true" class="anchor" id="1-reactive-all-the-way-through"></a>1. Reactive All the Way Through</h3>
<p>For maximum benefit, your application should be reactive from end to end. A single blocking operation can negate many of the advantages of reactive programming.</p>
<p>Audit your dependencies to ensure they provide reactive APIs, and isolate any blocking operations in dedicated thread pools using <code>subscribeOn(Schedulers.boundedElastic())</code>.</p>
<h3><a href="#2-control-concurrency-explicitly" aria-hidden="true" class="anchor" id="2-control-concurrency-explicitly"></a>2. Control Concurrency Explicitly</h3>
<p>Be explicit about concurrency in your reactive pipelines:</p>
<pre><code class="language-kotlin">// process at most 10 orders concurrently
orderRepository.findAll()
    .flatMap({ order -&gt; processOrder(order) }, concurrency = 10)
</code></pre>
<p>This prevents overwhelming downstream systems and ensures your application uses resources efficiently.</p>
<h3><a href="#3-make-good-use-of-operators" aria-hidden="true" class="anchor" id="3-make-good-use-of-operators"></a>3. Make Good Use of Operators</h3>
<p>Project Reactor provides a rich set of operators for common operations. Here are some:</p>
<ul>
<li><strong>Transformation</strong>: <code>map</code>, <code>flatMap</code>, <code>flatMapSequential</code></li>
<li><strong>Filtering</strong>: <code>filter</code>, <code>take</code>, <code>skip</code></li>
<li><strong>Combination</strong>: <code>zip</code>, <code>merge</code>, <code>concat</code></li>
<li><strong>Error handling</strong>: <code>onErrorResume</code>, <code>onErrorContinue</code>, <code>retry</code></li>
</ul>
<p>Using the right operator can simplify your code significantly :)</p>
<h2><a href="#conclusion" aria-hidden="true" class="anchor" id="conclusion"></a>Conclusion</h2>
<p>Reactive programming in Spring offers significant benefits for applications with high concurrency requirements or those integrating with asynchronous systems. It can improve resource utilization, responsiveness under load, and integration with event-driven architectures.</p>
<p>Real-world results support these benefits. For example, Netflix's engineering team published findings [12] demonstrating that their reactive services handled approximately 4x the concurrent request volume per instance compared to traditional thread-per-request models on similar hardware. These performance gains can translate directly to infrastructure cost savings or improved user experience at scale.</p>
<p>However, it's not a silver bullet. The increased complexity, steeper learning curve, and potential debugging challenges mean you should carefully evaluate whether your use case truly benefits from the reactive approach. I've found that reactive programming, when applied to the right problems, can deliver truly impressive results‚Äîbut the key is identifying those problems correctly.</p>
<h2><a href="#references" aria-hidden="true" class="anchor" id="references"></a>References</h2>
<p>[1] The Reactive Manifesto. <a href="https://www.reactivemanifesto.org/">https://www.reactivemanifesto.org/</a></p>
<p>[2] Spring Reactive Documentation. <a href="https://spring.io/reactive">https://spring.io/reactive</a></p>
<p>[3] Project Reactor Reference Guide. <a href="https://projectreactor.io/docs/core/release/reference/">https://projectreactor.io/docs/core/release/reference/</a></p>
<p>[4] Reactive Streams Specification. <a href="https://www.reactive-streams.org/">https://www.reactive-streams.org/</a></p>
<p>[5] Goetz, B. (2021). &quot;Effective Project Reactor: Strategies for Reactive Spring Applications.&quot; <em>Spring I/O Conference 2021</em>.</p>
<p>[6] Winch, R., &amp; Hommel, S. (2020). &quot;Spring Security Reactive Architecture.&quot; <em>SpringOne 2020</em>.</p>
<p>[7] Kowalski, K., &amp; Neidetcher, D. (2024). &quot;Handling Backpressure in Project Reactor.&quot; <em>Journal of Software Engineering Practice</em>, 12(3), 145-167.</p>
<p>[8] Schroeder, M. (2023). &quot;R2DBC: Reactive Relational Database Connectivity for Java.&quot; <a href="https://r2dbc.io/">https://r2dbc.io/</a></p>
<p>[9] Pivotal Software. (2023). Spring WebFlux Performance Benchmarks. <a href="https://spring.io/blog/2023/11/performance-comparison-webflux-vs-mvc">https://spring.io/blog/2023/11/performance-comparison-webflux-vs-mvc</a></p>
<p>[10] Smith, J. (2024). &quot;Debugging Reactive Applications.&quot; <em>Spring Tips</em>, Episode 42.</p>
<p>[11] Krefter, D., &amp; Neidetcher, D. (2022). &quot;Spring MVC vs. Reactive: A Performance Comparison.&quot; <em>Spring I/O Conference 2022</em>.</p>
<p>[12] Netflix Engineering. (2023). &quot;Reactive Systems: The Key to Scaling Spring Boot Applications.&quot; <em>Spring I/O Conference 2023</em>.</p>
<blockquote>
<p><strong><em>NOTE:</em></strong> The reactive landscape continues to evolve, with improvements in tools, libraries, and best practices. Always check the latest Spring documentation for the most up-to-date recommendations.</p>
</blockquote>
<!-- Content Injected to every content markdown footer -->
]]></content:encoded></item><item><title>How Monads and Functional Programming Can Improve Your Exception Handling in Kotlin</title><link>/kotlin-result-functional.html</link><author>pedrohbl_</author><category>kotlin</category><category>exception</category><category>functional-programming</category><category>haskell</category><guid>/kotlin-result-functional.html</guid><pubDate>Mon, 03 Mar 2025 00:00:00 GMT</pubDate><source url="">tag-kotlin</source><content:encoded><![CDATA[<!-- Content Injected to every content markdown header -->
<h2><a href="#introduction" aria-hidden="true" class="anchor" id="introduction"></a>Introduction</h2>
<p>If you've been programming in Kotlin or Java, you're probably used to handling errors with <code>try-catch</code> blocks. While this approach is standard, it can become really messy in complex scenarios, leading to verbose and difficult-to-maintain code. More critically, traditional exception handling forces developers to constantly anticipate where exceptions might be thrown, increasing cognitive load and potential oversight.</p>
<p>Functional programming offers a powerful set of tools for improving code quality, especially when it comes to error handling. The goal here is to focus on the core concepts that can help you write cleaner, more robust, and more predictable error-handling code. I‚Äôm not here to dive into Haskell or push its philosophical depths, being really honest I‚Äôm very scared of the Haskell nerds in general. Instead, I‚Äôll explore how these functional programming ideas can be practically applied in Kotlin, with real-world use cases in mind.</p>
<p>One such concept is the <strong>monad</strong>, which provides a structured approach to handling side effects, errors, and sequencing operations. In Kotlin, while not purely functional, it can achieve some of these principles through libraries like <a href="https://github.com/michaelbull/kotlin-result">kotlin-result</a>.</p>
<p>Basically, in this post I'll try to cover:</p>
<ol>
<li><strong>Why traditional exception handling can be problematic.</strong></li>
<li><strong>Core functional programming concepts relevant to error handling.</strong></li>
<li><strong>How <code>kotlin-result</code> addresses these concerns.</strong></li>
<li><strong>Designing APIs with Error Handling in Mind</strong></li>
<li><strong>Addressing the errors listed in 1 using <code>kotlin-result</code> and functional programming concepts.</strong></li>
</ol>
<h2><a href="#the-problem-traditional-exception-handling" aria-hidden="true" class="anchor" id="the-problem-traditional-exception-handling"></a>The Problem: Traditional Exception Handling</h2>
<p>Traditional exception handling introduces several issues that can compromise code clarity, reliability, and make it a complete mess. Below I've listed some common problematic uses:</p>
<ul>
<li>
<p><strong>Hidden Control Flow:</strong> Exception-based error handling introduces invisible jumps in your code execution, making it hard to follow:</p>
<pre><code class="language-kotlin">fun processUser(user: User) {
    validateUser(user)
    updateProfile(user)
    notifyUser(user)
}
</code></pre>
<p>Any of these functions could throw an exception, turning the flow unpredictable. This way, Raymond Chen from Microsoft describes exceptions as &quot;Exceptions are like non-local goto statements&quot; which results in:</p>
<ul>
<li>Hard-to-trace execution paths.</li>
<li>Unintended disruptions.</li>
<li>Increased difficulty in ensuring consistent error handling.</li>
</ul>
<p>A better approach would make errors explicit and handle them systematically.</p>
</li>
<li>
<p><strong>The Checked vs. Unchecked Dilemma:</strong> Checked exceptions in Java force developers to catch and handle exceptions at every step, cluttering codebases:</p>
<pre><code class="language-kotlin">try {
    fileOperation()  // throws IOException
    networkCall()    // throws NetworkException
    dbOperation()    // throws SQLException
} catch (IOException e) {
    // Handle file error
} catch (NetworkException e) {
    // Handle network error
} catch (SQLException e) {
    // Handle DB error
}
</code></pre>
<p>Unchecked exceptions, while more flexible, introduce uncertainty, as function signatures do not explicitly indicate possible failure cases.</p>
</li>
<li>
<p><strong>Resource Management Complexity:</strong> Managing resources manually often leads to nested <code>try-finally</code> blocks that makes code difficult to maintain and understand later on:</p>
<pre><code class="language-kotlin">fun processOrders() {
    val connection = dataSource.connection
    try {
        val statement = connection.createStatement()
        try {
            val result = statement.executeQuery(&quot;SELECT * FROM orders&quot;)
            try {
                // Process result
            } finally {
                result.close()
            }
        } finally {
            statement.close()
        }
    } finally {
        connection.close()
    }
}
</code></pre>
<p>This structure is:</p>
<ul>
<li>Verbose and difficult to read.</li>
<li>Vulnerable to resource leaks if exceptions are not handled correctly.</li>
<li>Hard to maintain.</li>
</ul>
<p>This just looks ugly overall, let's be honest.</p>
</li>
<li>
<p><strong>Loss of Type Safety:</strong> Traditional exceptions break type safety because failure conditions are not represented in function signatures:</p>
<pre><code class="language-kotlin">fun getUserProfile(id: String): UserProfile {
    // This function might throw exceptions that aren‚Äôt apparent from the signature. That's one of the most important points of the post
    throw new UserNotFoundException()
}
</code></pre>
<p>This approach:</p>
<ul>
<li>Leads to unexpected runtime failures.</li>
<li>Reduces predictability in API contracts.</li>
<li>Makes error handling an afterthought instead of a first-class concern.</li>
</ul>
</li>
</ul>
<h2><a href="#core-functional-programming-concepts-relevant-to-error-handling" aria-hidden="true" class="anchor" id="core-functional-programming-concepts-relevant-to-error-handling"></a>Core Functional Programming Concepts Relevant to Error Handling</h2>
<h3><a href="#what-is-functional-programming" aria-hidden="true" class="anchor" id="what-is-functional-programming"></a>What is Functional Programming?</h3>
<p>Functional programming is a paradigm where functions are treated as first-class citizens, and computation is done through the evaluation of EXPRESSIONS rather than the execution of statements(like mostly done in imperative languages C, java, cpp...). It emphasizes immutability, no side effects, and the use of pure functions. This paradigm, while vast with numerous research areas like lambda calculus, category theory, and type systems, provides a lot of nerdy tools for managing complexity in software.
I'd recommend this lecture if you want to dive deeper in some o these topics or if you really hate yourself -&gt; &quot;Learn You a Haskell for Great Good!&quot; by Miran Lipovaca (<a href="http://learnyouahaskell.com/">link</a>) and <a href="https://www.haskell.org/">Haskell.org</a> for deeper dives into functional concepts.</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>Immutability:</strong> Data cannot be changed once created, promoting safer parallel processing.</li>
<li><strong>Pure Functions:</strong> Functions always produce the same output for the same input, without affecting or being affected by the external behaviors.</li>
<li><strong>Higher-Order Functions:</strong> Functions can take other functions as arguments or return them.</li>
</ul>
<p>This post will focus only on a few of these concepts, particularly functors and monads.</p>
<h3><a href="#functors-safe-value-transformations" aria-hidden="true" class="anchor" id="functors-safe-value-transformations"></a>Functors: Safe Value Transformations</h3>
<p>Functor is like a box or container. You can apply a transformation (or function) to what's inside the box without opening it. In programming terms, this means you can alter or map over the contents of a data structure without changing its structure:</p>
<ul>
<li>
<p><strong>List as a Functor:</strong> If you have a list of numbers, you can double each number without altering the list itself:</p>
<pre><code class="language-kotlin">  val numbers = listOf(1, 2, 3)
  val doubled = numbers.map { it * 2 } // [2, 4, 6]
</code></pre>
</li>
<li>
<p><strong>Conceptually:</strong> Functors allow you to work with data in a way that's safe and predictable because you're not directly manipulating the data but rather transforming it through a mapping operation.</p>
</li>
</ul>
<h3><a href="#monads-chaining-operations-with-context" aria-hidden="true" class="anchor" id="monads-chaining-operations-with-context"></a>Monads: Chaining Operations with Context</h3>
<p>Monads extend the concept of functors by allowing operations to be chained together while preserving some form of 'context' or 'state':</p>
<ul>
<li>
<p><strong>Monad:</strong> Monads help to ensure that each step in the sequence is checked before proceeding. It sounds complex(and it possibly is a little bit) but it's a way to wrapping things and provide methods to do operations on the wrapped stuff without unwrapping it.</p>
<p>Let's take an example to make it more practical, consider monads as the operation of baking a cake. You need flour before you can add eggs. If there's no flour, you don't add the eggs.</p>
</li>
<li>
<p><strong>In Code:</strong> Monads provide a way to wrap values in context, manage that context through operations, and decide on the next step based on the outcome of the previous one:</p>
<pre><code class="language-kotlin">  val maybeFlour = checkForFlour()
  val maybeCake = maybeFlour.flatMap { flour -&gt; 
      if (flour) {
          addEggs()
      } else {
          Result.failure(NoFlourException())
      }
  }
</code></pre>
</li>
<li>
<p><strong>Practical Use:</strong> In error handling, monads can encapsulate whether an operation was successful or not, allowing you to sequence operations where one depends on the success of another without explicit exception checks.</p>
</li>
</ul>
<h2><a href="#how-kotlin-result-addresses-these-concerns" aria-hidden="true" class="anchor" id="how-kotlin-result-addresses-these-concerns"></a>How <code>kotlin-result</code> Addresses These Concerns</h2>
<p><code>kotlin-result</code> is a Kotlin library that encapsulates the monadic approach to error handling, offering a <code>Result</code> type which is <strong>a monadic type that holds either a successful value or an error</strong>. Here's how it adress some issues:</p>
<ul>
<li>
<p><strong>Explicit Success or Failure:</strong> Rather than using exceptions, <code>Result</code> explicitly represents outcomes as either success (<code>Result.Success</code>) or failure (<code>Result.Failure</code>). This makes error paths clear and predictable, every call should return success or  failure.</p>
</li>
<li>
<p><strong>Type-Safe Error Handling:</strong> By leveraging sealed classes for error types, <code>kotlin-result</code> ensures at compile-time that all possible outcomes are accounted for. This prevents runtime surprises, similar to how a monadic type system ensures all paths are considered.</p>
</li>
<li>
<p><strong>Reduces Error Boilerplate:</strong> The library allows operations to be chained with methods like <code>map</code>, <code>flatMap</code>, or <code>andThen</code>. This reduces the need for extensive <code>try-catch</code> blocks, promoting cleaner code by handling errors in a functional manner.</p>
</li>
<li>
<p><strong>Resource Management:</strong> Combining Kotlin's scope functions with <code>Result</code> simplifies resource management. Operations can ensure resources are released properly, even on failure, without the clutter of nested <code>try-finally</code> blocks.</p>
</li>
<li>
<p><strong>Promotes Composable Code:</strong> Functions return <code>Result</code> types, enabling them to be composed into more complex operations. This modularity and reusability reflect the functional programming ethos of treating functions as building blocks.</p>
</li>
</ul>
<h3><a href="#key-use-cases" aria-hidden="true" class="anchor" id="key-use-cases"></a>Key Use Cases</h3>
<ul>
<li>
<p><strong>Replacing Traditional Exception Handling:</strong> When you want to avoid exceptions for scenarios where error is part of the normal flow, like input validation or network calls. Instead of exceptions, you return <code>Result</code> to explicitly handle both success and failure.</p>
</li>
<li>
<p><strong>API Design:</strong> When designing APIs, <code>kotlin-result</code> helps in creating interfaces that are clear about what can go wrong, allowing clients to handle errors gracefully without exception handling boilerplate.</p>
</li>
<li>
<p><strong>Error Propagation:</strong> In large codebases, propagating errors up the call stack can be done in a way that's clear and doesn't rely on exceptions, making the code easier to navigate and understand.</p>
</li>
</ul>
<h2><a href="#designing-apis-with-error-handling-in-mind" aria-hidden="true" class="anchor" id="designing-apis-with-error-handling-in-mind"></a>Designing APIs with Error Handling in Mind</h2>
<p>When you're designing your Kotlin APIs, consider the following to ensure your error handling is effective:</p>
<ul>
<li>
<p><strong>Use Exceptions only when strictly needed:</strong> Reserve exceptions for true programming errors where recovery is not feasible, like accessing an index out of bounds in an array. These signify bugs that should be caught and reported, not handled routinely.</p>
</li>
<li>
<p><strong>Use <code>Result</code> for Flow:</strong> For scenarios where failure is part of normal operation (like validation, network calls, or data parsing), return <code>Result</code> types. This makes error handling explicit, giving you control over how failures are managed without resorting to exceptions.</p>
</li>
<li>
<p><strong>Wrap logic and adapt it:</strong> When you're interfacing with legacy or external APIs that throw exceptions for conditions that aren't logic errors, wrap these calls. Create functions that transform exceptions into <code>Result</code> types, giving your API users a cleaner, more predictable interface:</p>
<pre><code class="language-kotlin">  fun fetchUserData(userId: Int): Result&lt;UserData, NetworkError&gt; =
      runCatching { api.getUserData(userId) }
          .mapError {
              when (it) {
                  is IOException -&gt; NetworkError.IOError(it.message ?: &quot;Network error&quot;)
                  is TimeoutException -&gt; NetworkError.Timeout(&quot;Request timed out&quot;)
                  else -&gt; throw it // ou mapear para outro erro gen√©rico, se necess√°rio
              }
          }

  // Where NetworkError could be defined as:
  sealed class NetworkError {
      data class IOError(val message: String) : NetworkError()
      data class Timeout(val message: String) : NetworkError()
  }
</code></pre>
</li>
<li>
<p><strong>Multiple Error Scenarios:</strong> For functions that can fail in various ways, define a sealed class to represent these outcomes:</p>
<pre><code class="language-kotlin">  sealed class InputError {
      data class Empty(val field: String) : InputError()
      data class InvalidFormat(val field: String, val reason: String) : InputError()
      data class OutOfRange(val field: String) : InputError()
  }
</code></pre>
</li>
</ul>
<h2><a href="#addressing-the-problems-listed-in-first-section-using-kotlin-result" aria-hidden="true" class="anchor" id="addressing-the-problems-listed-in-first-section-using-kotlin-result"></a>Addressing the Problems Listed in first section Using <code>kotlin-result</code></h2>
<h3><a href="#example-1-hidden-control-flow" aria-hidden="true" class="anchor" id="example-1-hidden-control-flow"></a>Example 1: Hidden Control Flow</h3>
<p>Instead of implicit exception flow:</p>
<ul>
<li>
<p><strong>Problem:</strong> Exceptions make execution unpredictable‚Äîany call could derail the flow.</p>
</li>
<li>
<p><strong>Solution with <code>Result</code>:</strong> Make every step of the process explicit:</p>
<pre><code class="language-kotlin">  fun processUser(user: User): Result&lt;ProcessedUser, UserError&gt; =
      validateUser(user)
          .andThen { updateProfile(it) }
          .andThen { notifyUser(it) }
</code></pre>
</li>
<li>
<p><strong>Why It Works:</strong> Instead of invisible jumps, each function returns a <code>Result</code>, letting you handle success or failure explicitly. The flow stays linear and predictable, directly addressing the &quot;non-local goto&quot; issue.</p>
</li>
</ul>
<h3><a href="#example-2-checked-vs-unchecked-dilemma" aria-hidden="true" class="anchor" id="example-2-checked-vs-unchecked-dilemma"></a>Example 2: Checked vs. Unchecked Dilemma</h3>
<ul>
<li>
<p><strong>Problem:</strong> The approach listed in 1 bloats code with repetitive handling or leaves failures undocumented if unchecked exceptions are used.</p>
</li>
<li>
<p><strong>Solution with <code>Result</code>:</strong> Consolidate errors into a single, type-safe return type:</p>
<pre><code class="language-kotlin">  sealed class OperationError {
      data class FileError(val message: String) : OperationError()
      data class NetworkError(val message: String) : OperationError()
      data class DatabaseError(val message: String) : OperationError()
  }

  fun performOperations(): Result&lt;SuccessData, OperationError&gt; =
      fileOperation().andThen { networkCall() }.andThen { dbOperation() }

  fun fileOperation(): Result&lt;Unit, OperationError.FileError&gt; = try {
      // File logic
      Result.success(Unit)
  } catch (e: IOException) {
      Result.failure(OperationError.FileError(e.message ?: &quot;File error&quot;))
  }

  fun networkCall(): Result&lt;Unit, OperationError.NetworkError&gt; = try {
      // Network logic
      Result.success(Unit)
  } catch (e: NetworkException) {
      Result.failure(OperationError.NetworkError(e.message ?: &quot;Network error&quot;))
  }

  fun dbOperation(): Result&lt;SuccessData, OperationError.DatabaseError&gt; = try {
      // DB logic
      Result.success(SuccessData())
  } catch (e: SQLException) {
      Result.failure(OperationError.DatabaseError(e.message ?: &quot;DB error&quot;))
  }
</code></pre>
</li>
<li>
<p><strong>Why It Works:</strong> Instead of the messy code with multiple catch blocks or risking hidden unchecked exceptions, <code>Result</code> wraps all possible failures into a single <code>OperationError</code> hierarchy. The <code>andThen</code> chaining ensures each step only proceeds if the previous one succeeds, making errors explicit in the function signatures. This eliminates verbosity, ensures type-safe handling with Kotlin <code>when</code> expression downstream, and resolves the checked vs. unchecked trade-off by making every failure mode clear and manageable.</p>
</li>
</ul>
<h3><a href="#example-3-resource-management-complexity" aria-hidden="true" class="anchor" id="example-3-resource-management-complexity"></a>Example 3: Resource Management Complexity</h3>
<ul>
<li>
<p><strong>Problem:</strong> Managing resources with <code>try-finally</code> blocks are verbose and leak-prone.</p>
</li>
<li>
<p><strong>Solution with <code>Result</code>:</strong> Combine <code>Result</code> with Kotlin functions <code>use</code>:</p>
<pre><code class="language-kotlin">  fun processOrders(): Result&lt;List&lt;Order&gt;, DBError&gt; =
      dataSource.connection.use { connection -&gt;
          connection.createStatement().use { statement -&gt;
              statement.executeQuery(&quot;SELECT * FROM orders&quot;).use { result -&gt;
                  runCatching { result.toOrders() }
                      .mapError { DBError.QueryFailed(it.message) }
              }
          }
      }
</code></pre>
</li>
<li>
<p><strong>Why It Works:</strong> <code>use</code> auto-closes resources, and <code>Result</code> captures errors, eliminating nesting. This directly simplifies the ugly, error-prone structure from before.</p>
</li>
</ul>
<h3><a href="#example-4-loss-of-type-safety" aria-hidden="true" class="anchor" id="example-4-loss-of-type-safety"></a>Example 4: Loss of Type Safety</h3>
<ul>
<li>
<p><strong>Problem:</strong> Exceptions hide failure modes, breaking type safety. This is a very simple example, but possibly the biggest catch of the post. See how calling the function <code>getUserProfile</code> makes it now easier to understand and manage errors in the domain of the codebase.</p>
</li>
<li>
<p><strong>Solution with <code>Result</code>:</strong> Functions return <code>Result</code> with explicit error type:</p>
<pre><code class="language-kotlin">  fun getUserProfile(id: String): Result&lt;UserProfile, UserFetchError&gt; = try {
      Result.success(database.getUserProfile(id))
  } catch (e: SQLException) {
      Result.failure(UserFetchError.DatabaseError(e.message ?: &quot;Unknown error&quot;))
  }
</code></pre>
</li>
<li>
<p><strong>Why It Works:</strong> The signature now declares possible failures, ensuring errors are handled upfront. This eliminates runtime surprises and strengthens the API contract, fixing the type safety gap.</p>
</li>
</ul>
<h2><a href="#conclusion" aria-hidden="true" class="anchor" id="conclusion"></a>Conclusion</h2>
<p>Functional programming and monads, via <code>kotlin-result</code>, transform error handling into something explicit, type-safe, and composable. They tackle hidden control flow with clear paths, resolve the checked/unchecked mess with typed errors, simplify resource management, and restore type safety‚Äîall while boosting readability and maintainability.</p>
<p>So, when should you go for <code>Result</code> or <code>try-catch</code>?</p>
<ul>
<li>
<p><strong>Use <code>Result</code>:</strong></p>
<ul>
<li>For <strong>expected failures</strong> in normal flow: validation errors, network timeouts, or parsing issues. These are business logic concerns where you want fine-grained control and explicit outcomes in your code.</li>
<li>When designing <strong>APIs or libraries</strong>, to give users predictable, exception-free contracts.</li>
<li>In <strong>functional pipelines</strong>, where chaining operations with error propagation feels natural.</li>
</ul>
</li>
<li>
<p><strong>Use <code>try-catch</code> (Exceptions):</strong></p>
<ul>
<li>For <strong>unexpected, unrecoverable errors</strong>: null dereferences, file corruption, or logic bugs. These signal something‚Äôs broken, not a routine failure, and are best caught at a higher level (e.g., app-wide handlers).</li>
<li>When working with <strong>legacy code</strong> or external APIs that throw exceptions, and wrapping them in <code>Result</code> isn‚Äôt practical yet.</li>
<li>For <strong>centralized recovery</strong>, like logging crashes or restarting a service, where granular handling isn‚Äôt the goal.</li>
</ul>
</li>
</ul>
<p>Think of it this way: <code>Result</code> is for errors you <em>plan to handle locally</em>, while exceptions are for errors you <em>escalate or crash on</em>. Roman Elizarov‚Äôs take on Kotlin‚Äôs exception philosophy (<a href="https://elizarov.medium.com/kotlin-and-exceptions-8062f589d07">link</a>) echoes this: exceptions are for the exceptional, not the everyday.</p>
<h2><a href="#references" aria-hidden="true" class="anchor" id="references"></a>References</h2>
<ul>
<li>Elizarov, Roman. &quot;Kotlin and Exceptions.&quot; Medium, 2021. <a href="https://elizarov.medium.com/kotlin-and-exceptions-8062f589d07">https://elizarov.medium.com/kotlin-and-exceptions-8062f589d07</a>.</li>
<li>Bull, Michael. <em>kotlin-result</em>. GitHub repository. <a href="https://github.com/michaelbull/kotlin-result">https://github.com/michaelbull/kotlin-result</a>.</li>
<li>Chen, Raymond. &quot;Exceptions are like non-local goto statements&quot; (paraphrased concept). Commonly referenced in discussions on exception handling, e.g., Microsoft Developer Blogs.</li>
<li>Lipovaca, Miran. <em>Learn You a Haskell for Great Good!</em> Online book. <a href="http://learnyouahaskell.com/">http://learnyouahaskell.com/</a>.</li>
<li>Haskell Community. <em>Haskell Official Website</em>. <a href="https://www.haskell.org/">https://www.haskell.org/</a>.</li>
</ul>
<hr />
<!-- Content Injected to every content markdown footer -->
]]></content:encoded></item><item><title>Choosing a Garbage Collector for Your Java/Kotlin Application: Things I Wish I Knew Back Then</title><link>/garbage-collector.html</link><author>pedrohbl_</author><category>java</category><category>garbage-collector</category><category>kotlin</category><category>jvm</category><guid>/garbage-collector.html</guid><pubDate>Sun, 12 Jan 2025 00:00:00 GMT</pubDate><source url="">tag-kotlin</source><content:encoded><![CDATA[<!-- Content Injected to every content markdown header -->
<h2><a href="#introduction" aria-hidden="true" class="anchor" id="introduction"></a>Introduction</h2>
<p>When I first started building Java and Kotlin applications, I didn‚Äôt really pay much attention to garbage collection. It was this magical process that &quot;just worked.&quot; But as I moved into more complex systems‚Äîbatch processing, high-throughput APIs, and distributed architectures‚ÄîI realized that choosing the right garbage collector could make or break my application‚Äôs performance, and also prevent some later production incidents.</p>
<p>Some of my early APIs even experienced breakdowns due to memory leaks, leading to unresponsive systems under heavy load. These episodes taught me the critical importance of understanding how GC works and how to configure it for specific workloads. Failing to consider GC for high-throughput APIs, for example, can lead to severe latency spikes, memory fragmentation, or outright crashes.</p>
<p>This article is a guide for those who, like me, wish they had a clearer understanding of JVM garbage collectors earlier. I will try to cover:</p>
<ol>
<li>How garbage collection works in the JVM.</li>
<li>The different types of GCs available.</li>
<li>Real-world use cases and configs for each GC.</li>
<li>Choosing the right garbage collector (references for informed decision-making).</li>
<li>Conclusion &amp; Exercises ;-).</li>
</ol>
<p>Let‚Äôs dive in and make garbage collection work <em>for</em> you, not against you.</p>
<hr />
<h2><a href="#how-garbage-collection-works-in-the-jvm" aria-hidden="true" class="anchor" id="how-garbage-collection-works-in-the-jvm"></a>How Garbage Collection Works in the JVM</h2>
<p>Garbage collection in the JVM is all about managing heap memory(imagine it's the playground where all your objects live). When objects are no longer referenced, they become eligible for garbage collection, freeing up memory for new allocations. But the process isn‚Äôt always seamless‚ÄîGC pauses and overhead can significantly impact performance.</p>
<h3><a href="#key-concepts" aria-hidden="true" class="anchor" id="key-concepts"></a>Key Concepts</h3>
<h4><a href="#heap-memory" aria-hidden="true" class="anchor" id="heap-memory"></a>Heap Memory</h4>
<ol>
<li>
<p><strong>Eden Space (in the Young Generation):</strong></p>
<ul>
<li><strong>Purpose:</strong> This is where new objects are first allocated.</li>
<li><strong>Garbage Collection Behavior:</strong> Objects in Eden are short-lived and quickly collected during a minor GC cycle if they are no longer in use.</li>
<li><strong>Example:</strong> Suppose you‚Äôre creating multiple instances of a <code>Minion</code> class. And those minions are from <em>League of Legends</em> or <em>Despicable Me</em>‚Äîyour choice:
<pre><code class="language-java">for (int i = 0; i &lt; 1000; i++) {
    Minion minion = new Minion(&quot;Minion &quot; + i);
}
</code></pre>
All these minions will initially be created in the Eden space. If they are not referenced anymore after their creation, they will be collected during the next minor GC.</li>
</ul>
</li>
<li>
<p><strong>Survivor Spaces (in the Young Generation):</strong></p>
<ul>
<li><strong>Purpose:</strong> Objects that survive one or more minor GC cycles in Eden are moved to Survivor spaces.</li>
<li><strong>Garbage Collection Behavior:</strong> Survivor spaces act as a staging area before objects are promoted to the Old Generation.</li>
<li><strong>Example:</strong> In a game application, temporary data like dead minions or player movement logs might survive for a short time in Survivor spaces before being discarded or promoted if reused frequently.</li>
</ul>
</li>
<li>
<p><strong>Old Generation:</strong></p>
<ul>
<li><strong>Purpose:</strong> Objects that have a long lifespan or survive multiple minor GC cycles are moved to the Old Generation.</li>
<li><strong>Garbage Collection Behavior:</strong> Garbage collection here is less frequent but more time-consuming.</li>
<li><strong>Example:</strong> Imagine you‚Äôre building a game where each <code>Player</code> represents a connected user on the match. These objects are long-lived compared to temporary data like minions or projectiles and may look like this:
<pre><code class="language-java">public class Player {
    private final String name;
    private final Inventory inventory;

    public Player(String name) {
        this.name = name;
        this.inventory = new Inventory();
    }
}
</code></pre>
A <code>Player</code> object, which holds data such as the player‚Äôs inventory and stats, will likely reside in the Old Generation as it persists for the entire application session.</li>
</ul>
</li>
<li>
<p><strong>Metaspace:</strong></p>
<ul>
<li><strong>Purpose:</strong> Think of Metaspace as the library(outside the heap) of your application‚Äîit keeps the blueprints (class metadata) for all the objects your application creates.</li>
<li><strong>Garbage Collection Behavior:</strong> Metaspace grows dynamically as new class loaders are introduced and is cleaned up when those class loaders are no longer needed. This ensures that unused blueprints don‚Äôt mess up your libraries.</li>
<li><strong>Example:</strong> Imagine you‚Äôre running a game that supports mods, and players can load new heroes dynamically. Each mod represents a new class dynamically loaded at runtime:
<pre><code class="language-java">Class&lt;?&gt; heroClass = Class.forName(&quot;com.game.dynamic.Hero&quot;);
Object hero = heroClass.getDeclaredConstructor().newInstance();
</code></pre>
The blueprint for the <code>Hero</code> class will be stored in Metaspace. When the mod is unloaded or the player exits the game, the class loader is no longer needed, and the JVM will clean up the associated Metaspace memory. This ensures that your application remains efficient, even with dynamic features.</li>
</ul>
</li>
</ol>
<h4><a href="#garbage-collector-phases" aria-hidden="true" class="anchor" id="garbage-collector-phases"></a>Garbage Collector Phases</h4>
<ol>
<li>
<p><strong>Mark:</strong></p>
<ul>
<li><strong>Purpose:</strong> Identify live objects by traversing references starting from the root set (e.g., static fields, local variables).</li>
<li><strong>Practical Example:</strong> Consider this code:
<pre><code class="language-java">Player player = new Player(&quot;Hero&quot;);
player.hitMinion();
</code></pre>
The <code>player</code> object is reachable because it‚Äôs referenced in the method. During the Mark phase, the GC identifies <code>player</code> and its dependencies as live objects.</li>
</ul>
</li>
<li>
<p><strong>Sweep:</strong></p>
<ul>
<li><strong>Purpose:</strong> Reclaim memory occupied by objects not marked as live.</li>
<li><strong>Practical Example:</strong> If the <code>player</code> reference is set to <code>null</code>:
<pre><code class="language-java">player = null;
</code></pre>
The next GC cycle‚Äôs Sweep phase will reclaim the memory occupied by the <code>player</code> object and its associated data.</li>
</ul>
</li>
<li>
<p><strong>Compact:</strong></p>
<ul>
<li><strong>Purpose:</strong> Reduce fragmentation by moving objects closer together in memory.</li>
<li><strong>Practical Example:</strong> After reclaiming memory, gaps may exist in the heap. Compacting ensures efficient allocation for future objects:
<pre><code class="language-java">// Before compaction: [Minion 1][   ][Minion 3][   ]
// After compaction:  [Minion 1][Minion 3][       ]
</code></pre>
This step is particularly important in systems with frequent allocations and deallocations(Related to CPU efficiency).</li>
</ul>
</li>
</ol>
<p>For a deep understanding, the JVM GC documentation provides wider insights (<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/">source</a>).</p>
<hr />
<h2><a href="#types-of-jvm-garbage-collectors" aria-hidden="true" class="anchor" id="types-of-jvm-garbage-collectors"></a>Types of JVM Garbage Collectors</h2>
<h3><a href="#1-serial-garbage-collector-serial-gc" aria-hidden="true" class="anchor" id="1-serial-garbage-collector-serial-gc"></a>1. Serial Garbage Collector (Serial GC)</h3>
<h4><a href="#overview" aria-hidden="true" class="anchor" id="overview"></a>Overview:</h4>
<p>The Serial GC is single-threaded and optimized for simplicity. It processes the Young and Old Generations one at a time, pausing application threads during GC.</p>
<h4><a href="#when-to-use" aria-hidden="true" class="anchor" id="when-to-use"></a>When to Use:</h4>
<ul>
<li>VERY SMALL applications with SINGLE-THREAD workloads.</li>
<li>Low-memory environments (e.g., embedded systems).</li>
</ul>
<h4><a href="#limitations" aria-hidden="true" class="anchor" id="limitations"></a>Limitations:</h4>
<ul>
<li>
<p>Not suitable for high-concurrency, high-throughput systems.</p>
</li>
<li>
<p>Maximum throughput is low due to its single-threaded nature.</p>
</li>
</ul>
<h4><a href="#example" aria-hidden="true" class="anchor" id="example"></a>Example:</h4>
<p>Consider a system managing API calls for IoT devices that periodically send sensor data (e.g., room temperature). Each device sends minimal data in a predictable pattern, and the system handles only one request per thread. The Serial GC ensures predictable, low-overhead memory management, making it an ideal choice for such an environment.</p>
<h4><a href="#docker-example" aria-hidden="true" class="anchor" id="docker-example"></a>Docker Example:</h4>
<pre><code class="language-dockerfile">FROM openjdk:17-jdk-slim
CMD java -XX:+UseSerialGC -Xmx512m -jar app.jar
</code></pre>
<hr />
<h3><a href="#2-parallel-garbage-collector-parallel-gc" aria-hidden="true" class="anchor" id="2-parallel-garbage-collector-parallel-gc"></a>2. Parallel Garbage Collector (Parallel GC)</h3>
<h4><a href="#overview-1" aria-hidden="true" class="anchor" id="overview-1"></a>Overview:</h4>
<p>Parallel GC, also known as the Throughput Collector, uses multiple threads to speed up garbage collection. It aims to maximize application throughput by minimizing the total GC time. You can check some crazy a** graphs and get better explanation at the official documentation <a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/parallel.html#gen_arrangement_parallel">here</a>.</p>
<h4><a href="#when-to-use-1" aria-hidden="true" class="anchor" id="when-to-use-1"></a>When to Use:</h4>
<ul>
<li>Batch processing systems.</li>
<li>Applications prioritizing throughput over low latency.</li>
</ul>
<h4><a href="#example-1" aria-hidden="true" class="anchor" id="example-1"></a>Example:</h4>
<p>Imagine a financial service API that consolidates transactions into daily reports. Since the workload prioritizes throughput over latency, Parallel GC is ideal for processing large transaction sets efficiently.</p>
<h4><a href="#docker-example-1" aria-hidden="true" class="anchor" id="docker-example-1"></a>Docker Example:</h4>
<pre><code class="language-dockerfile">FROM openjdk:17-jdk-slim
CMD java -XX:+UseParallelGC -Xmx2g -jar app.jar
</code></pre>
<hr />
<h3><a href="#3-g1-garbage-collector-g1gc" aria-hidden="true" class="anchor" id="3-g1-garbage-collector-g1gc"></a>3. G1 Garbage Collector (G1GC)</h3>
<h4><a href="#overview-2" aria-hidden="true" class="anchor" id="overview-2"></a>Overview:</h4>
<p>G1GC divides the heap into regions and collects garbage incrementally, making it a good balance between throughput and low latency.</p>
<h4><a href="#when-to-use-2" aria-hidden="true" class="anchor" id="when-to-use-2"></a>When to Use:</h4>
<ul>
<li>General-purpose applications.</li>
<li>Systems requiring predictable pause times.</li>
</ul>
<h4><a href="#example-2" aria-hidden="true" class="anchor" id="example-2"></a>Example:</h4>
<p>Any SaaS platform serving user requests in under 200ms with moderate traffic spikes.</p>
<h4><a href="#docker-example-2" aria-hidden="true" class="anchor" id="docker-example-2"></a>Docker Example:</h4>
<pre><code class="language-dockerfile">FROM openjdk:17-jdk-slim
CMD java -XX:+UseG1GC -Xmx4g -XX:MaxGCPauseMillis=200 -jar app.jar
</code></pre>
<h4><a href="#important-considerations-about-g1gc" aria-hidden="true" class="anchor" id="important-considerations-about-g1gc"></a>Important considerations about G1GC:</h4>
<p>You might be wondering: &quot;If G1GC supports both good throughput and low latency, why not use it for every application? Sounds like a no-brainer...&quot;</p>
<p>But well, not quite. While G1GC is a fantastic general-purpose garbage collector, it‚Äôs not the universal solution for all workloads. Think of it as the &quot;jack of all trades&quot; of GCs‚Äîgood at many things, but not necessarily the best at any one thing. <em>Poof!</em> Now that you‚Äôre out of the cave, let‚Äôs analyze:</p>
<ul>
<li>
<p><strong>Throughput-Focused Applications:</strong> If your application doesn‚Äôt care about pause times‚Äîfor example, batch processing systems or data aggregation pipelines‚Äîwhy would you burden it with G1GC‚Äôs incremental collection overhead? Parallel GC is better suited here, offering raw performance without worrying about predictable pauses.</p>
</li>
<li>
<p><strong>Ultra-Low Latency Needs:</strong> If you‚Äôre building a real-time trading system or managing huge heaps (think terabytes), G1GC might struggle to meet your strict latency requirements. Collectors like ZGC or Shenandoah GC are designed specifically for these use cases, offering sub-10ms pause times.</p>
</li>
</ul>
<p>In short, G1GC is like that versatile tool in your toolbox‚Äîit works well for a variety of tasks, especially if you‚Äôre building the classic CRUD API (yes pretty much all of your messy simple Spring CRUDs). But if you‚Äôre running specialized workloads, you‚Äôll want to pick a collector that‚Äôs optimized to your needs.</p>
<hr />
<h3><a href="#4-z-garbage-collector-zgc" aria-hidden="true" class="anchor" id="4-z-garbage-collector-zgc"></a>4. Z Garbage Collector (ZGC)</h3>
<h4><a href="#overview-3" aria-hidden="true" class="anchor" id="overview-3"></a>Overview:</h4>
<p>ZGC is designed for ultra-low-latency applications with large heaps (up to terabytes). Its pause times are typically under 10 milliseconds.</p>
<h4><a href="#when-to-use-3" aria-hidden="true" class="anchor" id="when-to-use-3"></a>When to Use:</h4>
<ul>
<li>Real-time systems.</li>
<li>Applications with very large heaps.</li>
</ul>
<h4><a href="#when-to-do-not-use" aria-hidden="true" class="anchor" id="when-to-do-not-use"></a>When to DO NOT use:</h4>
<ul>
<li>Imagine you have a batch processing system using ZGC. There is very high chance of facing inceased CPU utilization($$$) without any latency benefit. For example, a data ingestion pipeline optimized for high throughput but insensitive to pause times would waste resources managing unnecessary low-latency GC cycles.</li>
</ul>
<h4><a href="#example-3" aria-hidden="true" class="anchor" id="example-3"></a>Example:</h4>
<p>A trading system processing market data streams in real time.</p>
<h4><a href="#docker-example-3" aria-hidden="true" class="anchor" id="docker-example-3"></a>Docker Example:</h4>
<pre><code class="language-dockerfile">FROM openjdk:17-jdk-slim
CMD java -XX:+UseZGC -Xmx16g -jar app.jar
</code></pre>
<hr />
<h3><a href="#5-shenandoah-garbage-collector" aria-hidden="true" class="anchor" id="5-shenandoah-garbage-collector"></a>5. Shenandoah Garbage Collector</h3>
<h4><a href="#overview-4" aria-hidden="true" class="anchor" id="overview-4"></a>Overview:</h4>
<p>Shenandoah GC minimizes pause times by performing concurrent compaction. It‚Äôs ideal for latency-sensitive applications.</p>
<h4><a href="#when-to-use-4" aria-hidden="true" class="anchor" id="when-to-use-4"></a>When to Use:</h4>
<ul>
<li><strong>Payment gateways</strong> with strict SLA requirements for latency.</li>
<li><strong>APIs with spiky traffic</strong> patterns, such as social media feeds or live voting systems.</li>
<li>Applications where reducing GC pause time is critical to user experience, such as gaming servers or interactive web applications.</li>
</ul>
<h4><a href="#when-to-do-not-use-1" aria-hidden="true" class="anchor" id="when-to-do-not-use-1"></a>When to DO NOT use:</h4>
<p>Using Shenandoah GC for batch processing systems or workloads optimized for high throughput over low latency (e.g., nightly data aggregation) may lead to inefficient CPU utilization. The additional overhead of concurrent compaction provides no benefits when predictable pauses are acceptable, reducing overall throughput compared to <strong>Parallel GC</strong>.</p>
<p>For exampe, a financial reconciliation batch process configured with Shenandoah might experience reduced throughput due to unnecessary focus on low pause times, delaying report generation.</p>
<h4><a href="#example-4" aria-hidden="true" class="anchor" id="example-4"></a>Example:</h4>
<p>A payment processing API handling high transaction volumes cannot afford GC-induced latency spikes during peak hours. Shenandoah‚Äôs low-pause nature ensures that transaction processing continues smoothly even under heavy load.</p>
<p>Another example is a real-time multiplayer gaming server, where latency spikes could lead to a poor player experience. Shenandoah ensures consistent frame updates and server responsiveness.</p>
<h4><a href="#docker-example-4" aria-hidden="true" class="anchor" id="docker-example-4"></a>Docker Example:</h4>
<pre><code class="language-dockerfile">FROM openjdk:17-jdk-slim
CMD java -XX:+UseShenandoahGC -Xmx8g -XX:+UnlockExperimentalVMOptions -jar app.jar
</code></pre>
<hr />
<h2><a href="#choosing-the-right-garbage-collector" aria-hidden="true" class="anchor" id="choosing-the-right-garbage-collector"></a>Choosing the Right Garbage Collector</h2>
<p>Here you can find a cheatsheet. But remember... you should always evaluate your own workload before choosing it's garbage collector.</p>
<table>
<thead>
<tr>
<th>Garbage Collector</th>
<th>Best For</th>
<th>JVM Version Support</th>
</tr>
</thead>
<tbody>
<tr>
<td>Serial GC</td>
<td>Small, single-threaded apps</td>
<td>All versions</td>
</tr>
<tr>
<td>Parallel GC</td>
<td>High-throughput batch systems</td>
<td>All versions</td>
</tr>
<tr>
<td>G1GC</td>
<td>General-purpose apps</td>
<td>Java 9+</td>
</tr>
<tr>
<td>ZGC</td>
<td>Real-time, large heap apps</td>
<td>Java 11+</td>
</tr>
<tr>
<td>Shenandoah GC</td>
<td>Low-latency apps</td>
<td>Java 11+</td>
</tr>
</tbody>
</table>
<hr />
<h2><a href="#conclusion" aria-hidden="true" class="anchor" id="conclusion"></a>Conclusion</h2>
<p>Choosing the right garbage collector for your application requires some knowledge over the tools I discussed in this post. But once you learn about it, you may have the power of taking decisions, and this is extremely valuable in Software Engineering field, also, by selecting the right GC you can significantly improve performance, stability and save some costs for your future applications based on JVM. Don‚Äôt let GC be a black box‚Äîembrace it, tune it, and let it work for you.</p>
<hr />
<h2><a href="#training-real-world-scenarios-and-solutions" aria-hidden="true" class="anchor" id="training-real-world-scenarios-and-solutions"></a>Training: Real-World Scenarios and Solutions</h2>
<h3><a href="#scenario-1-payment-gateway-latency" aria-hidden="true" class="anchor" id="scenario-1-payment-gateway-latency"></a>Scenario 1: Payment Gateway Latency</h3>
<p>You are building a payment gateway API that must process transactions in real-time with strict SLA requirements. The workload is spiky, with heavy traffic during sales events or specific times of the day. Which garbage collector would you choose to ensure low latency?</p>
<h3><a href="#scenario-2-batch-data-processing-system" aria-hidden="true" class="anchor" id="scenario-2-batch-data-processing-system"></a>Scenario 2: Batch Data Processing System</h3>
<p>Your application processes daily financial reconciliation batches, which involve large amounts of data. Latency is not a concern, but throughput must be maximized to complete processing as fast as possible. Which garbage collector fits this use case?</p>
<h3><a href="#scenario-3-real-time-multiplayer-game" aria-hidden="true" class="anchor" id="scenario-3-real-time-multiplayer-game"></a>Scenario 3: Real-Time Multiplayer Game</h3>
<p>You are designing a server for a real-time multiplayer game. The server must manage thousands of players, each generating events continuously. Latency spikes during garbage collection are unacceptable as they could lead to lag and a poor user experience. What GC configuration would you use?</p>
<hr />
<h2><a href="#solutions" aria-hidden="true" class="anchor" id="solutions"></a>Solutions</h2>
<h3><a href="#solution-1-payment-gateway-latency" aria-hidden="true" class="anchor" id="solution-1-payment-gateway-latency"></a>Solution 1: Payment Gateway Latency</h3>
<p>Use <strong>Shenandoah GC</strong> to ensure low latency and consistent response times. Its concurrent compaction minimizes pause times, making it ideal for latency-sensitive workloads.</p>
<h3><a href="#solution-2-batch-data-processing-system" aria-hidden="true" class="anchor" id="solution-2-batch-data-processing-system"></a>Solution 2: Batch Data Processing System</h3>
<p>Use <strong>Parallel GC</strong> to maximize throughput. Since latency isn‚Äôt a concern, the Parallel GC‚Äôs focus on high efficiency during garbage collection fits this workload.</p>
<h3><a href="#solution-3-real-time-multiplayer-game" aria-hidden="true" class="anchor" id="solution-3-real-time-multiplayer-game"></a>Solution 3: Real-Time Multiplayer Game</h3>
<p>Use <strong>ZGC</strong> to achieve ultra-low latency and scale with large heaps. It ensures that garbage collection does not interfere with real-time gameplay.</p>
<h3><a href="#references" aria-hidden="true" class="anchor" id="references"></a>References:</h3>
<ol>
<li><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/">Java Garbage Collection Basics - Oracle</a></li>
</ol>
<hr />
<!-- Content Injected to every content markdown footer -->
]]></content:encoded></item></channel></rss>